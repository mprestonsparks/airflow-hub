# Airflow Hub & Market Analysis - Next Steps (Session starting 2025-04-25)

This plan outlines the immediate priorities based on the work completed on 2025-04-24 and a review of existing research notes.

## Priority 1: Verify Core Binance Integration

- **Goal:** Confirm the `market_analysis_ingestion` DAG successfully runs and connects to Binance using API keys passed via Airflow Variables (sourced from `market-analysis/.env`).
- **Action:**
    - [ ] Ensure Airflow services are running (`docker-compose up -d`).
    - [ ] Trigger the `market_analysis_ingestion` DAG in the Airflow UI ([http://localhost:8080](http://localhost:8080)).
    - [ ] Monitor the `ingest_market_data` task logs for successful execution and absence of authentication/connection errors.
    - [ ] Address any errors encountered during the run.

## Priority 2: Strategic Decision - DAG Structure Refactoring

- **Context:** Research file `(2025-04-22) DAG_RENAMING_RESEARCH.md` strongly recommends refactoring the `airflow-hub/dags/` directory from the current **Project-First** structure (`dags/project_trading/`, `dags/project_analytics/`, etc.) to a **Function-First** structure (`dags/ingestion/`, `dags/execution/`, `dags/transformation/`, `dags/analytics/`) for better scalability and clarity across multiple providers and workflows.
- **Action:**
    - [ ] **Discuss:** Decide whether to adopt the Function-First structure now or postpone the refactoring.
    - [ ] **If Yes (Refactor Now):**
        - [ ] Plan the specific steps: Create new directories (`ingestion`, `execution`, etc.).
        - [ ] Move existing DAGs (`market_analysis_ingestion.py`, `analytics_daily_etl.py`, any others) to their appropriate functional directories.
        - [ ] Rename DAG files according to a consistent convention (e.g., `{provider}_{asset/detail}_{workflow}.py` like `ingestion/binance_crypto_spot_ingestion.py`).
        - [ ] Update any imports or references affected by the move.
    - [ ] **If No (Postpone Refactoring):**
        - [ ] Acknowledge the current structure will be used for now.
        - [ ] Plan to revisit this decision later as the project grows.

## Priority 3: Address `analytics_daily_etl.py` DAG

- **Context:** This DAG is currently ignored via `.airflowignore` due to an import error.
- **Action (If time permits after P1 & P2):**
    - [ ] Remove `dags/project_analytics/analytics_daily_etl.py` from `.airflowignore`.
    - [ ] Restart Airflow services (`docker-compose down && docker-compose up -d`).
    - [ ] Observe the import error in the Airflow UI.
    - [ ] Debug and fix the error (likely a Python import issue or missing dependency *in the main Airflow environment*, not the task container).
    - [ ] Determine its correct location and name based on the decision made in Priority 2.

## Lower Priority / Technical Debt

- **TensorFlow Installation:** The current workaround in `Dockerfile.project_analytics` (commenting out `tensorflow` in `requirements.txt`, installing separately) works but could potentially be cleaned up later (e.g., checking for updated library compatibility, different base images).

---
*Generated by Cascade AI Assistant*
